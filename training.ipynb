{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T08:22:28.976792Z",
     "start_time": "2025-06-04T08:22:26.594658Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from classes import SpeedEstimatorRNN, VehicleSpeedDataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch"
   ],
   "id": "6be55e84bfa9497",
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T08:22:35.454138Z",
     "start_time": "2025-06-04T08:22:35.449925Z"
    }
   },
   "cell_type": "code",
   "source": [
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available! You can use a GPU for training.\")\n",
    "    print(\"Number of GPUs available:\", torch.cuda.device_count())\n",
    "    print(\"Current GPU being used:\", torch.cuda.current_device())\n",
    "    print(\"GPU Name:\", torch.cuda.get_device_name(torch.cuda.current_device()))\n",
    "else:\n",
    "    print(\"CUDA is not available. Training will be performed on the CPU.\")"
   ],
   "id": "223653cc21f3406c",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA is available! You can use a GPU for training.\n",
      "Number of GPUs available: 1\n",
      "Current GPU being used: 0\n",
      "GPU Name: NVIDIA GeForce RTX 3050 Laptop GPU\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T08:22:41.319243Z",
     "start_time": "2025-06-04T08:22:41.313997Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Set dataset path\n",
    "training_data_path = \"data/i7/it_1/1_training\"\n",
    "extension = \"*.csv\"\n",
    "\n",
    "test_data_path = \"data/i7/it_1/2_testing\"\n",
    "\n",
    "# Hyperparameters that will alter throughout the model creations\n",
    "input_size = 20  # Number of CAN signals per timestep\n",
    "hidden_size = [256, 256, 512, 512, 512]\n",
    "num_layers = [3, 4, 3, 4, 3]\n",
    "learning_rate = [0.0001] * 5\n",
    "# num of sequences in one batch\n",
    "batch_size = [128] * 5\n",
    "dropout_rate = [0.2] * 5\n",
    "sequence_length = [800, 800, 800, 800, 1000]\n",
    "\n",
    "\n",
    "# parameters of the simulation\n",
    "step_size = 10 # what the overlap between the sequences should look like in the extracted dataset\n",
    "output_size = 2\n",
    "num_epochs = 30\n",
    "\n",
    "num_models = 5\n",
    "\n",
    "location_state = \"Simple RNN/trained_models/i7/it_1/state_models/model_\"\n",
    "location_traced = \"Simple RNN/trained_models/i7/it_1/traced_models/model_\""
   ],
   "id": "65139ecfaf0a1ccf",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-06-04T10:34:34.643301Z",
     "start_time": "2025-06-04T08:27:38.125755Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# Initialize variables to track the best test/validation loss\n",
    "best_test_loss = float('inf')\n",
    "\n",
    "early_stopping_counter = 0\n",
    "patience = 5\n",
    "\n",
    "# Training loops\n",
    "for j in range(num_models):\n",
    "\n",
    "    early_stopping_counter = 0\n",
    "\n",
    "    # Load dataset and DataLoader\n",
    "    train_dataset = VehicleSpeedDataset(training_data_path, extension, seq_length = sequence_length[j], step_size = step_size)\n",
    "    train_dataloader = DataLoader(train_dataset, batch_size=batch_size[j], shuffle=True, num_workers= 6, pin_memory=True)\n",
    "\n",
    "    # Load test dataset and DataLoader\n",
    "    test_dataset = VehicleSpeedDataset(test_data_path, extension, seq_length=sequence_length[j], step_size=step_size)\n",
    "    test_dataloader = DataLoader(test_dataset, batch_size=1, shuffle=False)  # Batch size = 1 for test evaluation\n",
    "\n",
    "\n",
    "    # Initialize model, loss function, and optimizer\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = SpeedEstimatorRNN(input_size, hidden_size[j], num_layers[j], output_size).to(device)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate[j])\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        total_train_loss = 0\n",
    "\n",
    "        for batch_idx, (features, speeds) in enumerate(train_dataloader):\n",
    "            speeds = speeds.squeeze(1)  # Remove extra dimension from speeds if present\n",
    "            features, speeds = features.to(device), speeds.to(device)\n",
    "\n",
    "            # Forward pass\n",
    "            outputs = model(features)\n",
    "\n",
    "            assert outputs.shape == speeds.shape, f\"Shape mismatch: outputs {outputs.shape} vs speeds {speeds.shape}\"\n",
    "\n",
    "            train_loss = criterion(outputs, speeds)\n",
    "\n",
    "            # Backward pass\n",
    "            optimizer.zero_grad()\n",
    "            train_loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            total_train_loss += train_loss.item()\n",
    "\n",
    "        print(f\"Model: {j}, Epoch [{epoch+1}/{num_epochs}], Loss: {total_train_loss/len(train_dataloader):.4f}\")\n",
    "\n",
    "        model.eval()\n",
    "        total_test_loss = 0\n",
    "\n",
    "        with torch.no_grad():  # No need to compute gradients for validation/test\n",
    "            for features, speeds in test_dataloader:\n",
    "                speeds = speeds.squeeze(1)\n",
    "                features, speeds = features.to(device), speeds.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                test_outputs = model(features)\n",
    "                test_loss = criterion(test_outputs, speeds)\n",
    "\n",
    "                total_test_loss += test_loss.item()\n",
    "\n",
    "        avg_test_loss = total_test_loss / len(test_dataloader)\n",
    "\n",
    "        print(f\"Model: {j}, Epoch [{epoch+1}/{num_epochs}], Test Loss: {avg_test_loss:.4f}\")\n",
    "\n",
    "         # Checkpoint: Save model if test loss improves\n",
    "        if avg_test_loss < best_test_loss:\n",
    "            print(f\"New best model found! Test Loss improved from {best_test_loss:.4f} to {avg_test_loss:.4f}\")\n",
    "            best_test_loss = avg_test_loss\n",
    "            early_stopping_counter = 0\n",
    "\n",
    "            torch.save({\n",
    "                \"model_state_dict\": model.state_dict(),\n",
    "                \"optimizer_state_dict\": optimizer.state_dict(),\n",
    "                \"sequence_length\": sequence_length,\n",
    "                \"input_size\": input_size,\n",
    "                \"hidden_size\": hidden_size,\n",
    "                \"num_layers\": num_layers,\n",
    "                \"output_size\": output_size,\n",
    "                \"learning_rate\": learning_rate,\n",
    "                \"num_epochs\": num_epochs\n",
    "            }, location_state + str(j) + \".pt\")\n",
    "\n",
    "            # Save traced model for MATLAB\n",
    "            example_input = torch.rand(1, sequence_length[j], input_size).to(device)  # Example input matching model dimensions\n",
    "            traced_model = torch.jit.trace(model, example_input)\n",
    "            torch.jit.save(traced_model, location_traced + str(j) + \"_traced.pt\")  # Save as traced TorchScript model\n",
    "\n",
    "            print(f\"model_{j} saved\")\n",
    "        else:\n",
    "            early_stopping_counter += 1\n",
    "\n",
    "        if early_stopping_counter >= patience:\n",
    "            print(\"Early stopping triggered!\")\n",
    "            break  # Exit the training loop early\n",
    "\n",
    "\n"
   ],
   "id": "420abcdd902a5bd7",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: 0, Epoch [1/25], Loss: 11.8025\n",
      "Model: 0, Epoch [1/25], Test Loss: 6.7434\n",
      "New best model found! Test Loss improved from inf to 6.7434\n",
      "model_0 saved\n",
      "Model: 0, Epoch [2/25], Loss: 3.8498\n",
      "Model: 0, Epoch [2/25], Test Loss: 3.5973\n",
      "New best model found! Test Loss improved from 6.7434 to 3.5973\n",
      "model_0 saved\n",
      "Model: 0, Epoch [3/25], Loss: 2.1484\n",
      "Model: 0, Epoch [3/25], Test Loss: 2.1993\n",
      "New best model found! Test Loss improved from 3.5973 to 2.1993\n",
      "model_0 saved\n",
      "Model: 0, Epoch [4/25], Loss: 1.3396\n",
      "Model: 0, Epoch [4/25], Test Loss: 1.3858\n",
      "New best model found! Test Loss improved from 2.1993 to 1.3858\n",
      "model_0 saved\n",
      "Model: 0, Epoch [5/25], Loss: 0.8428\n",
      "Model: 0, Epoch [5/25], Test Loss: 0.8555\n",
      "New best model found! Test Loss improved from 1.3858 to 0.8555\n",
      "model_0 saved\n",
      "Model: 0, Epoch [6/25], Loss: 0.5280\n",
      "Model: 0, Epoch [6/25], Test Loss: 0.5428\n",
      "New best model found! Test Loss improved from 0.8555 to 0.5428\n",
      "model_0 saved\n",
      "Model: 0, Epoch [7/25], Loss: 0.3271\n",
      "Model: 0, Epoch [7/25], Test Loss: 0.3275\n",
      "New best model found! Test Loss improved from 0.5428 to 0.3275\n",
      "model_0 saved\n",
      "Model: 0, Epoch [8/25], Loss: 0.2099\n",
      "Model: 0, Epoch [8/25], Test Loss: 0.2112\n",
      "New best model found! Test Loss improved from 0.3275 to 0.2112\n",
      "model_0 saved\n",
      "Model: 0, Epoch [9/25], Loss: 0.1330\n",
      "Model: 0, Epoch [9/25], Test Loss: 0.1393\n",
      "New best model found! Test Loss improved from 0.2112 to 0.1393\n",
      "model_0 saved\n",
      "Model: 0, Epoch [10/25], Loss: 0.0884\n",
      "Model: 0, Epoch [10/25], Test Loss: 0.0980\n",
      "New best model found! Test Loss improved from 0.1393 to 0.0980\n",
      "model_0 saved\n",
      "Model: 0, Epoch [11/25], Loss: 0.0598\n",
      "Model: 0, Epoch [11/25], Test Loss: 0.0737\n",
      "New best model found! Test Loss improved from 0.0980 to 0.0737\n",
      "model_0 saved\n",
      "Model: 0, Epoch [12/25], Loss: 0.0405\n",
      "Model: 0, Epoch [12/25], Test Loss: 0.0574\n",
      "New best model found! Test Loss improved from 0.0737 to 0.0574\n",
      "model_0 saved\n",
      "Model: 0, Epoch [13/25], Loss: 0.0317\n",
      "Model: 0, Epoch [13/25], Test Loss: 0.0504\n",
      "New best model found! Test Loss improved from 0.0574 to 0.0504\n",
      "model_0 saved\n",
      "Model: 0, Epoch [14/25], Loss: 0.0244\n",
      "Model: 0, Epoch [14/25], Test Loss: 0.0599\n",
      "Model: 0, Epoch [15/25], Loss: 0.0210\n",
      "Model: 0, Epoch [15/25], Test Loss: 0.0400\n",
      "New best model found! Test Loss improved from 0.0504 to 0.0400\n",
      "model_0 saved\n",
      "Model: 0, Epoch [16/25], Loss: 0.0178\n",
      "Model: 0, Epoch [16/25], Test Loss: 0.0374\n",
      "New best model found! Test Loss improved from 0.0400 to 0.0374\n",
      "model_0 saved\n",
      "Model: 0, Epoch [17/25], Loss: 0.0137\n",
      "Model: 0, Epoch [17/25], Test Loss: 0.0420\n",
      "Model: 0, Epoch [18/25], Loss: 0.0130\n",
      "Model: 0, Epoch [18/25], Test Loss: 0.0392\n",
      "Model: 0, Epoch [19/25], Loss: 0.0117\n",
      "Model: 0, Epoch [19/25], Test Loss: 0.0366\n",
      "New best model found! Test Loss improved from 0.0374 to 0.0366\n",
      "model_0 saved\n",
      "Model: 0, Epoch [20/25], Loss: 0.0122\n",
      "Model: 0, Epoch [20/25], Test Loss: 0.0375\n",
      "Model: 0, Epoch [21/25], Loss: 0.0102\n",
      "Model: 0, Epoch [21/25], Test Loss: 0.0375\n",
      "Model: 0, Epoch [22/25], Loss: 0.0098\n",
      "Model: 0, Epoch [22/25], Test Loss: 0.0375\n",
      "Model: 0, Epoch [23/25], Loss: 0.0088\n",
      "Model: 0, Epoch [23/25], Test Loss: 0.0470\n",
      "Model: 0, Epoch [24/25], Loss: 0.0086\n",
      "Model: 0, Epoch [24/25], Test Loss: 0.0391\n",
      "Early stopping triggered!\n",
      "Model: 1, Epoch [1/25], Loss: 12.3521\n",
      "Model: 1, Epoch [1/25], Test Loss: 7.1719\n",
      "Early stopping triggered!\n",
      "Model: 2, Epoch [1/25], Loss: 5.6428\n",
      "Model: 2, Epoch [1/25], Test Loss: 2.0456\n",
      "Early stopping triggered!\n",
      "Model: 3, Epoch [1/25], Loss: 6.6216\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[31m---------------------------------------------------------------------------\u001B[39m",
      "\u001B[31mKeyboardInterrupt\u001B[39m                         Traceback (most recent call last)",
      "\u001B[36mCell\u001B[39m\u001B[36m \u001B[39m\u001B[32mIn[9]\u001B[39m\u001B[32m, line 57\u001B[39m\n\u001B[32m     54\u001B[39m features, speeds = features.to(device), speeds.to(device)\n\u001B[32m     56\u001B[39m \u001B[38;5;66;03m# Forward pass\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m57\u001B[39m test_outputs = \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfeatures\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     58\u001B[39m test_loss = criterion(test_outputs, speeds)\n\u001B[32m     60\u001B[39m total_test_loss += test_loss.item()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32mC:\\my files\\thesis\\AI_training\\classes.py:24\u001B[39m, in \u001B[36mSpeedEstimatorRNN.forward\u001B[39m\u001B[34m(self, x)\u001B[39m\n\u001B[32m     21\u001B[39m h0 = torch.zeros(\u001B[38;5;28mself\u001B[39m.num_layers, x.size(\u001B[32m0\u001B[39m), \u001B[38;5;28mself\u001B[39m.hidden_size).to(x.device)\n\u001B[32m     23\u001B[39m \u001B[38;5;66;03m# Forward pass through RNN\u001B[39;00m\n\u001B[32m---> \u001B[39m\u001B[32m24\u001B[39m out, _ = \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mrnn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mh0\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m     26\u001B[39m \u001B[38;5;66;03m# Take the output from the last timestep\u001B[39;00m\n\u001B[32m     27\u001B[39m out = \u001B[38;5;28mself\u001B[39m.fc(out[:, -\u001B[32m1\u001B[39m, :])  \u001B[38;5;66;03m# Now this will work correctly\u001B[39;00m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001B[39m, in \u001B[36mModule._wrapped_call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1737\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m._compiled_call_impl(*args, **kwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[32m   1738\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m-> \u001B[39m\u001B[32m1739\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001B[39m, in \u001B[36mModule._call_impl\u001B[39m\u001B[34m(self, *args, **kwargs)\u001B[39m\n\u001B[32m   1745\u001B[39m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[32m   1746\u001B[39m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[32m   1747\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m._backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m._forward_pre_hooks\n\u001B[32m   1748\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[32m   1749\u001B[39m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[32m-> \u001B[39m\u001B[32m1750\u001B[39m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[43m*\u001B[49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43m*\u001B[49m\u001B[43m*\u001B[49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m   1752\u001B[39m result = \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[32m   1753\u001B[39m called_always_called_hooks = \u001B[38;5;28mset\u001B[39m()\n",
      "\u001B[36mFile \u001B[39m\u001B[32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\torch\\nn\\modules\\rnn.py:716\u001B[39m, in \u001B[36mRNN.forward\u001B[39m\u001B[34m(self, input, hx)\u001B[39m\n\u001B[32m    714\u001B[39m \u001B[38;5;28;01mif\u001B[39;00m batch_sizes \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[32m    715\u001B[39m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m.mode == \u001B[33m\"\u001B[39m\u001B[33mRNN_TANH\u001B[39m\u001B[33m\"\u001B[39m:\n\u001B[32m--> \u001B[39m\u001B[32m716\u001B[39m         result = \u001B[43m_VF\u001B[49m\u001B[43m.\u001B[49m\u001B[43mrnn_tanh\u001B[49m\u001B[43m(\u001B[49m\n\u001B[32m    717\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[32m    718\u001B[39m \u001B[43m            \u001B[49m\u001B[43mhx\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    719\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43m_flat_weights\u001B[49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# type: ignore[arg-type]\u001B[39;49;00m\n\u001B[32m    720\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbias\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    721\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mnum_layers\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    722\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mdropout\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    723\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mtraining\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    724\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbidirectional\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    725\u001B[39m \u001B[43m            \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[43m.\u001B[49m\u001B[43mbatch_first\u001B[49m\u001B[43m,\u001B[49m\n\u001B[32m    726\u001B[39m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[32m    727\u001B[39m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[32m    728\u001B[39m         result = _VF.rnn_relu(\n\u001B[32m    729\u001B[39m             \u001B[38;5;28minput\u001B[39m,\n\u001B[32m    730\u001B[39m             hx,\n\u001B[32m   (...)\u001B[39m\u001B[32m    737\u001B[39m             \u001B[38;5;28mself\u001B[39m.batch_first,\n\u001B[32m    738\u001B[39m         )\n",
      "\u001B[31mKeyboardInterrupt\u001B[39m: "
     ]
    }
   ],
   "execution_count": 9
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
